# MiniGrid-Empty-v0:
#   env_type: GymMiniGrid
#   # env_size: 62
#   # abs_ticks:
#   # - [15, 30, 60]
#   # - [20, 40, 60]
#   # - [30, 45, 60]
#   # env_size: 86
#   # abs_ticks:
#   # - [28, 56, 84]
#   env_size: 32
#   # abs_ticks:
#   #   - [5, 10, 30]
#   # - [10, 20, 30]
#   #   - [20, 25, 30]
#   agent_start_pos: [1, 1]
#   total_timesteps: 50000
#   init_steps: 5000
#   input_format: full_obs
#   grd_hidden_dims:
#     - 8
#     - 16
#     - 32
#   grd_embedding_dim: 64
#   encoder_detach: True
#   use_shaping: True
#   # cluster_embedding_dim: None
#   n_clusters: 4
#   # lr_ground_Q: 0.0002
#   # lr_abstract_V: 0.1
#   lr_ground_Q: lin_0.0002
#   lr_abstract_V: 0.01
#   lr_tcurl: 0.0001
#   # lr_encoder: 0.0005
#   # lr_decoder: 0.0005
#   batch_size: 256
#   size_replay_memory: 30000
#   gamma: 0.99
#   abstract_gamma: 0.99
#   omega: 10
#   ground_Q_encoder_tau: 1
#   ground_Q_critic_tau: 1
#   # abstract_tau: 0.2
#   # encoder_tau: 0.2
#   exploration_fraction: 1
#   exploration_initial_eps: 0.6
#   exploration_final_eps: 0.01
#   save_model_every: 500000.0
#   tcurl_learn_every: 4
#   ground_learn_every: 4
#   ground_sync_every: 8
#   ground_gradient_steps: 1
#   abstract_learn_every: 1000
#   abstract_sync_every: 4
#   abstract_gradient_steps: 1000
#   # learn_with_ae: True
#   # init_clustering: True
#   # wandb_group: AE_KMeans_DQN
#   # wandb_group: AE_DQN
#   wandb_group: tcurl_shp_env32_50k_buf30k
#   # wandb_group: shp_100k_lrabs0.1_tau0.1_aevery4_rrward_mod
#   wandb_notes: nothing
#   # wandb_tags: ["shp", "omg1", "tbl", "16x16", "(1,1)"]
#   clip_grad: True
#   # validate_every: 1000
#   reset_training_info_every: 1000
#   save_recon_every: 1000
#   # buffer_recent_states_every: 1000

MiniGrid-Empty-v0:
  env_type: GymMiniGrid
  env_size: 32
  agent_start_pos: [1, 1]
  total_timesteps: 150000
  init_steps: 3000
  input_format: full_obs
  grd_hidden_channels:
    - 8
    - 16
    - 32
  grd_embedding_dim: 32
  encoded_detach4abs: False
  use_shaping: True
  # cluster_embedding_dim: None
  num_vq_embeddings: 10
  dim_vq_embeddings: 32
  vq_softmin_beta: 50
  mlp_hidden_dim_abs: 64
  mlp_hidden_dim_grd: 64
  # lr_ground_Q: 0.0002
  # lr_abstract_V: 0.1
  lr_ground_Q: lin_0.0002
  lr_abstract_V: 0.0001
  lr_vq: 0.0001
  # lr_encoder: 0.0005
  # lr_decoder: 0.0005
  batch_size: 256
  size_replay_memory: 50000
  gamma: 0.99
  abstract_gamma: 0.99
  omega: 10
  ground_Q_encoder_tau: 0.05
  ground_Q_critic_tau: 0.05
  abstract_tau: 1
  # encoder_tau: 0.2
  exploration_fraction: 1
  exploration_initial_eps: 0.6
  exploration_final_eps: 0.01
  save_model_every: 500000.0
  tcurl_learn_every: 4
  ground_learn_every: 4
  ground_sync_every: 64
  ground_gradient_steps: 1
  abstract_learn_every: 0
  abstract_sync_every: 8
  abstract_gradient_steps: 0
  clip_grad: False
  clip_reward: False
  # wandb_group: AE_KMeans_DQN
  # wandb_group: AE_DQN
  wandb_group: e2e_shp_env50_50k_buf50k#EncDetach_SoftVQ
  # wandb_group: shp_100k_lrabs0.1_tau0.1_aevery4_rrward_mod
  wandb_notes: nothing
  # wandb_tags: ["shp", "omg1", "tbl", "16x16", "(1,1)"]

  # validate_every: 1000
  reset_training_info_every: 1000
  save_recon_every: 1000
  # buffer_recent_states_every: 1000

MiniGrid-FourRooms-v0:
  env_type: GymMiniGrid
  env_size: 19
  agent_start_pos: [1, 1]
  goal_pos: [17, 17]
  total_timesteps: 300000
  init_steps: 5000
  input_format: full_obs
  grd_hidden_channels:
    - 8
    - 16
    - 32
  grd_embedding_dim: 32
  encoded_detach4abs: False
  use_shaping: True
  # cluster_embedding_dim: None
  num_vq_embeddings: 10
  dim_vq_embeddings: 32
  vq_softmin_beta: 1
  mlp_hidden_dim_abs: 64
  mlp_hidden_dim_grd: 64
  # lr_ground_Q: 0.0002
  # lr_abstract_V: 0.1
  lr_ground_Q: 0.0005
  lr_abstract_V: 0.0005
  lr_vq: 0.0005
  # lr_encoder: 0.0005
  # lr_decoder: 0.0005
  batch_size: 256
  size_replay_memory: 50000
  gamma: 0.99
  abstract_gamma: 0.99
  omega: 10
  ground_Q_encoder_tau: 0.05
  ground_Q_critic_tau: 0.05
  abstract_tau: 1
  # encoder_tau: 0.2
  exploration_fraction: 0.95
  exploration_initial_eps: 1.0
  exploration_final_eps: 0.01
  save_model_every: 500000.0
  tcurl_learn_every: 4
  ground_learn_every: 4
  ground_sync_every: 64
  ground_gradient_steps: 1
  abstract_learn_every: 0
  abstract_sync_every: 8
  abstract_gradient_steps: 0
  clip_grad: False
  clip_reward: False
  # wandb_group: AE_KMeans_DQN
  # wandb_group: AE_DQN
  wandb_group: e2e_shp_env19_100k_buf50k_vqbeta1_atc#12
  # wandb_group: shp_100k_lrabs0.1_tau0.1_aevery4_rrward_mod
  wandb_notes: total_loss = ground_td_error + vq_loss - entrophy_vq + commit_error_abs2grd(abs_v, grd_q_target)

  # wandb_tags: ["shp", "omg1", "tbl", "16x16", "(1,1)"]

  # validate_every: 1000
  reset_training_info_every: 1000
  save_recon_every: 1000
  # buffer_recent_states_every: 1000
